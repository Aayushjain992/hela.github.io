<!DOCTYPE html>
<html>
<head>
  <title>x</title>
</head>
<body>
  <button onclick="copyMultilineText1()">1</button>
  <button onclick="copyMultilineText2()">2</button>
  <button onclick="copyMultilineText3()">3</button>
  <button onclick="copyMultilineText4()">4</button>
  <button onclick="copyMultilineText5()">5</button>
  <button onclick="copyMultilineText6()">6</button>
  <button onclick="copyMultilineText7()">7</button>
  <button onclick="copyMultilineText8()">8</button>
  <button onclick="copyMultilineText9()">9</button>
  <button onclick="copyMultilineText10()">10</button>
  <button onclick="copyMultilineText11()">11</button>
  <button onclick="copyMultilineText12()">12</button>
  <script>
    function copyToClipboard(text) {
      navigator.clipboard.writeText(text)
        .catch(err => {
          console.error('Error copying text: ', err);
        });
    }

    function copyMultilineText1() {
      var yourMultilineVariable = `#Importing the required packages

import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

df1 = pd.read_csv(r'/content/movies.csv')
df2 = pd.read_csv(r'/content/ratings.csv')
df = df2.merge(df1, left_on='movieId', right_on='movieId', how='left')
df

del df['timestamp']
del df['genres']
df.head()
user_movie_matrix = pd.pivot_table(df, values = 'rating', index='movieId', columns = 'userId')
user_movie_matrix
user_movie_matrix = user_movie_matrix.fillna(0)
user_movie_matrix.head()
#user-based collaborative filtering 

user_user_matrix = user_movie_matrix.corr(method='pearson')
user_user_matrix
#Extarcing top 10 similar users for User2 by sorting them in descending order based on their similarties



user_user_matrix.loc[2].sort_values(ascending=False).head(10)
df_2 = pd.DataFrame(user_user_matrix.loc[2].sort_values(ascending=False).head(10))
df_2 = df_2.reset_index()
df_2.columns = ['userId', 'similarity']
df_2 = df_2.drop((df_2[df_2['userId'] ==2]).index)
df_2
#Now we are creating a new DF which has all the similar users and their rated movies

final_df = df_2.merge(df, left_on='userId', right_on='userId', how='left')
final_df
final_df['score'] = final_df['similarity']*final_df['rating']
final_df
watched_df = df[df['userId'] == 2]
watched_df
cond = final_df['movieId'].isin(watched_df['movieId'])
final_df.drop(final_df[cond].index, inplace = True)
recommended_df = final_df.sort_values(by = 'score', ascending = False)['title'].head(10)
recommended_df = recommended_df.reset_index()
del recommended_df['index']
recommended_df

`;
      copyToClipboard(yourMultilineVariable);
    }

    function copyMultilineText2() {
      var yourMultilineVariable = `import os
import sys
from pathlib import Path

import pandas as pd
import numpy as np

# Options for pandas
pd.options.display.max_columns = 50
pd.options.display.max_rows = 30
pd.options.display.float_format = '{:,.4f}'.format

# autoreload extension
%load_ext autoreload
%autoreload 2


sys.path.insert(0, str(Path.cwd().parent))

import ast
from PIL import Image
REPO_PATH = Path.cwd()

report_path = '/content/BigData_sizes.csv'
df = pd.read_csv(report_path, converters={'logo_path': str, 'description_html': str,
                                          'logo_rendering': ast.literal_eval,
                                          'arrow_specs': ast.literal_eval
                                          })

df

sort_idx = df.sort_values('size_PB').index
df.loc[sort_idx]

import plotly.graph_objects as go

big_lbls = df.loc[df.size_label.str.contains('EB'), 'size_label']
df.loc[df.size_label.str.contains('EB'), 'size_label'] = ''


layout = {
    'template': "plotly_white",
    'paper_bgcolor': 'rgba(0,0,0,0)',
    'plot_bgcolor': 'rgba(0,0,0,0)',
    'title': {
        'x': 0.5, 'xanchor': 'center'
    },
    'font': dict(
        family="Helvetica",
        size=18,
    ),
    'showlegend': False,
    'autosize': False,
    'width': 1400,
    'height': 720,
    'margin': dict(l=0, r=0, t=0, b=0),
}

# Bubble plot
fig = go.Figure(data=[
    go.Scatter(
        x=df.x, y=df.size_PB,
        #         x0=1,dx=6,
        mode='markers+text',
        marker=dict(
            size=df.area_size,
            color=df.color,
            opacity=[0.7]*(df.shape[0]-1) + [0.4],
            sizemin=12,
            sizemode='area',
            sizeref=2. * df.area_size.max() / (840 ** 2)
        ),
        text=df.size_label.str.replace('yr', 'y'),
        textposition='bottom center',
        textfont=dict(size=14),
    )
]
)

# Big bubbles labels
fig.add_trace(go.Scatter(
    x=[42, 74, 71],
    y=[20000, 3800, 25],
    mode="text",
    text=big_lbls,
    textposition="bottom center",
    textfont=dict(size=[14, 14, 18])
))

# Image annotations
logos_path = REPO_PATH / "/content/"

for v in df[['logo_path', 'logo_rendering']].itertuples():
    if not v.logo_path:
        continue
    src = Image.open(logos_path / v.logo_path)  # logos_path + v.logo_path

    xpos, ypos, xs, ys = v.logo_rendering
    fig.add_layout_image(
        dict(
            source=src,
            xref="paper", yref="paper",
            x=xpos, y=ypos,
            sizex=xs, sizey=ys,
            xanchor="right", yanchor="bottom"
        )
    )


# Text annotations
for v in df[['description_html', 'arrow_specs']].itertuples():
    if not v.arrow_specs:
        continue
    xpos, ypos, xlen, ylen = v.arrow_specs
    fig.add_annotation(
        xref="x", yref="y domain",
        x=xpos, y=ypos,
        ax=xlen, ay=ylen,
        text=v.description_html,
        showarrow=True,
        arrowhead=0,
        font=dict(size=14),
    )

# Layout
fig.update_layout(
    yaxis=dict(
        type="log",
        range=[1, 7.5],
        visible=True,
    ),
    yaxis_title="log size (PB)",
    xaxis_title="source Aayush Jain 12",
    xaxis=dict(
        range=[-4.5, df.x.max()+2],
        visible=True,
        showticklabels=False,
    ),
)

fig.update_layout(layout)

fig.show()
`;
      copyToClipboard(yourMultilineVariable);
    }

    function copyMultilineText3() {
      var yourMultilineVariable = `import pandas as pd
import plotly.graph_objects as go

# Load the dataset
file_path = '/content/my_experiment.csv'
data = pd.read_csv(file_path)

# Ensure 'area_size' is numeric
data['area_size'] = pd.to_numeric(data['area_size'], errors='coerce')

# Handle missing or NaN values (if any)
data['area_size'] = data['area_size'].fillna(0)  # Replace NaN with 0 or use .dropna()

# Calculate sizeref after ensuring numeric values
sizeref = 2. * data['area_size'].max() / (840 ** 2)

# Prepare the layout for the plot
layout = {
    'template': "plotly_white",
    'paper_bgcolor': 'rgba(0,0,0,0)',
    'plot_bgcolor': 'rgba(0,0,0,0)',
    'title': {
        'text': "Storage Systems Visualization",
        'x': 0.5, 'xanchor': 'center'
    },
    'font': dict(
        family="Helvetica",
        size=18,
    ),
    'showlegend': False,
    'autosize': False,
    'width': 1400,
    'height': 720,
    'margin': dict(l=0, r=0, t=50, b=0),
    'images': [
        # Example of adding logos, adjust the 'x', 'y' coordinates and 'sizing'
        {
            'source': '/content/google_icon.png',  # Replace with the URL or path to the logo
            'xref': 'paper',  # Relative to paper coordinates
            'yref': 'paper',
            'x': 0.05,  # Horizontal position (between 0 and 1)
            'y': 0.95,  # Vertical position (between 0 and 1)
            'sizex': 0.1,  # Width as a fraction of the plot size
            'sizey': 0.1,  # Height as a fraction of the plot size
            'opacity': 0.7,
            'layer': 'above'
        },
        {
            'source': '/content/IBM.png',  # Replace with the URL or path to another logo
            'xref': 'paper',
            'yref': 'paper',
            'x': 0.9,
            'y': 0.05,
            'sizex': 0.1,
            'sizey': 0.1,
            'opacity': 0.7,
            'layer': 'above'
        }
    ]
}

# Create a bubble plot
fig = go.Figure(data=[
    go.Scatter(
        x=data['source'],
        y=data['size_PB'],
        mode='markers+text',
        marker=dict(
            size=data['area_size'],
            color=data['color'],
            opacity=0.7,
            sizemode='area',
            sizeref=sizeref
        ),
        text=data['source'],
        textposition='top center',
        textfont=dict(size=14),
    )
])

# Layout settings
fig.update_layout(
    yaxis=dict(
        type="linear",
        title="Size",
        visible=True,
    ),
    xaxis=dict(
        title="Storage",
        visible=True,
    )
)

fig.update_layout(layout)

# Show the plot
fig.show()
`;
      copyToClipboard(yourMultilineVariable);
    }

    function copyMultilineText4() {
      var yourMultilineVariable = `!pip install biopython

from  Bio import SeqIO
import matplotlib.pyplot as plt
fp="/content/sample.fasta"
for seq_record in SeqIO.parse(fp, "fasta"):
    print(seq_record.id)
    print(repr(seq_record.seq))
    print(len(seq_record))


def calculate_gc_content(sequence, window_size):

    gc_content = []
    for i in range(0, len(sequence) - window_size + 1):
        window = sequence[i:i + window_size]
        gc_count = window.count("G") + window.count("C")
        gc_content.append(gc_count / window_size * 100)
    return gc_content

# Example DNA sequence
dna_sequence = "ATGCGCGTAGCTAGGCTACGCGTACGTAGCGTAGCGTAGCTAGGCTAGCGTACGTAGC"
window_size = 10

# Calculate GC content
gc_values = calculate_gc_content(dna_sequence, window_size)

# Plot GC content
plt.figure(figsize=(10, 5))
plt.plot(range(len(gc_values)), gc_values, marker='o', linestyle='-', color='b')
plt.title(f"GC Content with Window Size {window_size}")
plt.xlabel("Window Position")
plt.ylabel("GC Content (%)")
plt.grid()
plt.show()
`;
      copyToClipboard(yourMultilineVariable);
    }
    function copyMultilineText5() {
      var yourMultilineVariable = `
from pyspark.sql import SparkSession
from pyspark.sql import Row
spark=SparkSession.builder.appName('TemperoryViewExample').getOrCreate()
data=[Row(id=1,name="ABC",age=25,city="ss"),Row(id=2,name="DEF",age=35,city="hi"),Row(id=3,name="GHI",age=15,city="ra"),Row(id=4,name="XYZ",age=38,city="js")]
df=spark.createDataFrame(data)
df.show()
df.createOrReplaceTempView("Employee")
result=spark.sql("select * from Employee")
result.show()
result1=spark.sql("select * from Employee where age>30")
result1.show()
#Sales 

data=[Row(1,"Electronic",1000,"2025-03-01"),
      Row(2,"Electronic",3000,"2025-01-01")]
columns=["sales_id","category","amount","date"]
df=spark.createDataFrame(data,columns)
df.createOrReplaceTempView("Sales")
result=spark.sql("select * from Sales")
result2=spark.sql("select category,AVG(amount) as Avg_Amt from Sales group by category")
result2.show()
result3=spark.sql("select * from Sales order by amount desc limit 1")
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
df_query1=result2.toPandas()
#barplot
plt.figure(figsize=(8,5))
sns.barplot(x="category",y="Avg_Amt",data=df_query1)
plt.title("Sales Amount by Category ")
plt.xlabel("Category")
plt.ylabel("Sales Amount")
plt.show()
`;
      copyToClipboard(yourMultilineVariable);
    }



    function copyMultilineText5() {
      var yourMultilineVariable = `
from pyspark.sql import SparkSession
from pyspark.sql import Row
spark=SparkSession.builder.appName('TemperoryViewExample').getOrCreate()
data=[Row(id=1,name="ABC",age=25,city="ss"),Row(id=2,name="DEF",age=35,city="hi"),Row(id=3,name="GHI",age=15,city="ra"),Row(id=4,name="XYZ",age=38,city="js")]
df=spark.createDataFrame(data)
df.show()
df.createOrReplaceTempView("Employee")
result=spark.sql("select * from Employee")
result.show()
result1=spark.sql("select * from Employee where age>30")
result1.show()
#Sales 

data=[Row(1,"Electronic",1000,"2025-03-01"),
      Row(2,"Electronic",3000,"2025-01-01")]
columns=["sales_id","category","amount","date"]
df=spark.createDataFrame(data,columns)
df.createOrReplaceTempView("Sales")
result=spark.sql("select * from Sales")
result2=spark.sql("select category,AVG(amount) as Avg_Amt from Sales group by category")
result2.show()
result3=spark.sql("select * from Sales order by amount desc limit 1")
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
df_query1=result2.toPandas()
#barplot
plt.figure(figsize=(8,5))
sns.barplot(x="category",y="Avg_Amt",data=df_query1)
plt.title("Sales Amount by Category ")
plt.xlabel("Category")
plt.ylabel("Sales Amount")
plt.show()
`;
      copyToClipboard(yourMultilineVariable);
    }

    function copyMultilineText6() {
      var yourMultilineVariable = `
from pyspark.sql import SparkSession
from pyspark.sql.functions import udf
from pyspark.sql.types import StringType

spark= SparkSession.builder.appName("UDF_Example").getOrCreate()
data=[("os",65),("pa",12),("jo",45)]
columns=["name","age"]
df=spark.createDataFrame(data,schema=columns)
df.printSchema()
def age_group(age):
  if age<18:
    return "Minor"
  elif age >= 18 and age <= 60:
    return "Adult"
  else:
    return "Senior Citizen"

age_group_udf=udf(age_group,StringType()) 
df=df.withColumn("age_group",age_group_udf(df["age"]))
df.show()
`;
      copyToClipboard(yourMultilineVariable);
    }

    function copyMultilineText7() {
      var yourMultilineVariable = `from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.regression import LinearRegression

spark = SparkSession.builder.appName("RegressionExample").getOrCreate()
data=[(1,100),(2,110),(3,120),(4,130),(5,105)]
columns=["feature","target"]
df=spark.createDataFrame(data,schema=columns)
df.show()
assembled=VectorAssembler(inputCols=["feature"],outputCol="features")
df=assembled.transform(df).select("features","target")
df.show()
lr=LinearRegression(featuresCol="features",labelCol="target")
lr_model=lr.fit(df)
print("Coefficients:",lr_model.coefficients)
print("Intercept:",lr_model.intercept)
training_summary=lr_model.summary
print("Root Mean Squared error:",training_summary.rootMeanSquaredError)
print("R2:",training_summary.r2)
prediction=lr_model.transform(df)
prediction.select("features","target","prediction").show()
`;
      copyToClipboard(yourMultilineVariable);
    }

    function copyMultilineText8() {
      var yourMultilineVariable = `from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.clustering import KMeans
spark=SparkSession.builder.appName('Kmeans').getOrCreate()
data=[(1.0,2.0),(1.5,1.8),(5.0,8.0),(8.0,8.0),(1.0,0.6),(9.0,11.0)]
columns=["sub1","sub2"]
df=spark.createDataFrame(data,columns)
df.show()
assembler=VectorAssembler(inputCols=["sub1","sub2"],outputCol="features")
res=assembler.transform(df)
res.show()
kmeans=KMeans(k=2,seed=1)
model=kmeans.fit(res)
prediction=model.transform(res)
prediction.show()
for center in model.clusterCenters():
  print(center)
`;
      copyToClipboard(yourMultilineVariable);
    }



    function copyMultilineText9() {
      var yourMultilineVariable = `
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.feature import CountVectorizer,IDF,Tokenizer
spark=SparkSession.builder.appName('Log').getOrCreate()
data=[(1,"Win a free Iphone"),(1,"You won a lottery"),(0,"Hello Lets meet for lunch"),(0,"Dont forget to complete the assignment")]
columns=["label","text"]
df=spark.createDataFrame(data,columns)
df.show()
tokenizer=Tokenizer(inputCol="text",outputCol="Tokens") # Now Tokenizer should be defined
res=tokenizer.transform(df)
res.show()
vectorizer=CountVectorizer(inputCol="Tokens",outputCol="features")
Vector_model=vectorizer.fit(res)
vec=Vector_model.transform(res)
vec.show()
idf=IDF(inputCol="features",outputCol="idf_features")
idf_model=idf.fit(vec)
res=idf_model.transform(vec)
res.show()
df1=res.select("label","idf_features")
lr=LogisticRegression(featuresCol="idf_features",labelCol="label")
model=lr.fit(df1)
prediction=model.transform(df1)
prediction.show()

`;
      copyToClipboard(yourMultilineVariable);
    }

    function copyMultilineText10() {
      var yourMultilineVariable = `from pyspark.sql import SparkSession
from pyspark.ml.classification import NaiveBayes
from pyspark.ml.feature import VectorAssembler, StringIndexer
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

spark = SparkSession.builder.appName("NaiveBayesWeather").getOrCreate()
data = [
    ("Sunny", 30, 50, 10),
    ("Rainy", 22, 85, 20),
    ("Cloudy", 25, 70, 15),
    ("Sunny", 35, 40, 8),
    ("Rainy", 20, 90, 25),
    ("Cloudy", 28, 65, 12),
    ("Sunny", 32, 45, 7),
    ("Rainy", 19, 95, 30),
    ("Cloudy", 26, 75, 18),
]
columns = ["weather", "temperature", "humidity", "wind_speed"]
df = spark.createDataFrame(data, columns)
df.show()
indexer = StringIndexer(inputCol="weather", outputCol="label")
df = indexer.fit(df).transform(df)
df.show()
vector_assembler = VectorAssembler(inputCols=["temperature", "humidity", "wind_speed"], outputCol="features")
df = vector_assembler.transform(df).select("label", "features")

train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)
nb = NaiveBayes(modelType="multinomial")
model = nb.fit(train_data)
predictions = model.transform(test_data)
evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictions)
print(f"Test Accuracy: {accuracy:.2f}")
predictions.select("label", "features", "prediction").show()


`;
      copyToClipboard(yourMultilineVariable);
    }



    function copyMultilineText11() {
      var yourMultilineVariable = `from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("WordCount").getOrCreate()
sc = spark.sparkContext  
data = [
    "hello world",
    "hello pyspark",
    "pyspark map reduce example",
    "reduce and map are powerful",
]
rdd = sc.parallelize(data)
mapped_rdd = rdd.flatMap(lambda line: line.split(" ")).map(lambda word: (word, 1))
word_counts = mapped_rdd.reduceByKey(lambda a, b: a + b)
result = word_counts.collect()
for word, count in result:
    print(f"{word}: {count}")
spark.stop()
`;
      copyToClipboard(yourMultilineVariable);
    }
    function copyMultilineText12() {
      var yourMultilineVariable = `from pyspark.sql import SparkSession
from pyspark.sql.functions import explode,split
from pyspark.sql.functions import col
spark=SparkSession.builder.appName('Word').getOrCreate()
data=[("Hello World",),("Hello , How are you",),("I am fine =",)]
columns=["text"]
df=spark.createDataFrame(data,columns)
df.show(truncate=False)
word_df=df.withColumn("words",explode(split(col("text")," ")))
word_df.show()
word_count=word_df.groupBy("words").count().orderBy(col('count').desc())
word_count.show()


`;
      copyToClipboard(yourMultilineVariable);
    }

  </script>
</body>
</html>
